{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584b6f91",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline\n",
    "This notebook loads the four raw CSVs, inspects them, normalizes each to a standard `text,label` schema, cleans text, deduplicates, and writes `train/val/test` CSVs to `data/processed/`.\n",
    "\n",
    "It is written to be runnable step-by-step with checks and explanatory notes so you can review intermediate outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0764a40",
   "metadata": {},
   "source": [
    "## 1) Setup and quick inspection\n",
    "Load libraries and provide helper used for quick head/tail/total checks (streaming tail to avoid loading full large files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d63fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 2.3.3\n",
      "Python packages imported: pandas, numpy, sklearn, tqdm, re, html, os, pathlib, collections \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Deep Learning Project\\ai_detector_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print('pandas', pd.__version__)\n",
    "print(\"Python packages imported: pandas, numpy, sklearn, tqdm, re, html, os, pathlib, collections \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72dff8b",
   "metadata": {},
   "source": [
    "## Load and Inspect Data Files\n",
    "Below we load each CSV into a DataFrame and show:\n",
    "- first few rows (.head())\n",
    "- column names\n",
    "- total rows\n",
    "\n",
    "This helps us decide how to standardize columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3c00a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC3 shape: (24322, 5)\n",
      "HC3 columns: ['question', 'human_answers', 'chatgpt_answers', 'index', 'source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_answers</th>\n",
       "      <th>chatgpt_answers</th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>['Basically there are many categories of \" Bes...</td>\n",
       "      <td>['There are many different best seller lists t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>['salt is good for not dying in car crashes an...</td>\n",
       "      <td>[\"Salt is used on roads to help melt ice and s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do we still have SD TV channels when HD lo...</td>\n",
       "      <td>[\"The way it works is that old TV stations got...</td>\n",
       "      <td>[\"There are a few reasons why we still have SD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has nobody assassinated Kim Jong - un He i...</td>\n",
       "      <td>[\"You ca n't just go around assassinating the ...</td>\n",
       "      <td>['It is generally not acceptable or ethical to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How was airplane technology able to advance so...</td>\n",
       "      <td>['Wanting to kill the shit out of Germans driv...</td>\n",
       "      <td>['After the Wright Brothers made the first pow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Why is every book I hear about a \" NY Times # ...   \n",
       "1  If salt is so bad for cars , why do we use it ...   \n",
       "2  Why do we still have SD TV channels when HD lo...   \n",
       "3  Why has nobody assassinated Kim Jong - un He i...   \n",
       "4  How was airplane technology able to advance so...   \n",
       "\n",
       "                                       human_answers  \\\n",
       "0  ['Basically there are many categories of \" Bes...   \n",
       "1  ['salt is good for not dying in car crashes an...   \n",
       "2  [\"The way it works is that old TV stations got...   \n",
       "3  [\"You ca n't just go around assassinating the ...   \n",
       "4  ['Wanting to kill the shit out of Germans driv...   \n",
       "\n",
       "                                     chatgpt_answers  index       source  \n",
       "0  ['There are many different best seller lists t...    NaN  reddit_eli5  \n",
       "1  [\"Salt is used on roads to help melt ice and s...    NaN  reddit_eli5  \n",
       "2  [\"There are a few reasons why we still have SD...    NaN  reddit_eli5  \n",
       "3  ['It is generally not acceptable or ethical to...    NaN  reddit_eli5  \n",
       "4  ['After the Wright Brothers made the first pow...    NaN  reddit_eli5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load HC3\n",
    "hc3_path = \"../data/raw/hc3.csv\"\n",
    "assert os.path.exists(hc3_path), f\"{hc3_path} not found\"\n",
    "\n",
    "df_hc3 = pd.read_csv(hc3_path)\n",
    "print(\"HC3 shape:\", df_hc3.shape)\n",
    "print(\"HC3 columns:\", df_hc3.columns.tolist())\n",
    "display(df_hc3.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e28d3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_generated shape: (1392522, 3)\n",
      "gpt_generated columns: ['source', 'id', 'text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>12 Years a Slave: An Analysis of the Film Essa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>20+ Social Media Post Ideas to Radically Simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "      <td>2022 Russian Invasion of Ukraine in Global Med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>human</td>\n",
       "      <td>3</td>\n",
       "      <td>533 U.S. 27 (2001) Kyllo v. United States: The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>4</td>\n",
       "      <td>A Charles Schwab Corporation Case Essay\\n\\nCha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  id                                               text\n",
       "0  human   0  12 Years a Slave: An Analysis of the Film Essa...\n",
       "1  human   1  20+ Social Media Post Ideas to Radically Simpl...\n",
       "2  human   2  2022 Russian Invasion of Ukraine in Global Med...\n",
       "3  human   3  533 U.S. 27 (2001) Kyllo v. United States: The...\n",
       "4  human   4  A Charles Schwab Corporation Case Essay\\n\\nCha..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load gpt_generated\n",
    "gpt_path = \"../data/raw/gpt_generated.csv\"\n",
    "assert os.path.exists(gpt_path), f\"{gpt_path} not found\"\n",
    "\n",
    "df_gpt = pd.read_csv(gpt_path)\n",
    "print(\"gpt_generated shape:\", df_gpt.shape)\n",
    "print(\"gpt_generated columns:\", df_gpt.columns.tolist())\n",
    "display(df_gpt.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b7826f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle_ai_human shape: (487235, 2)\n",
      "kaggle_ai_human columns: ['text', 'generated']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Cars. Cars have been around since they became ...        0.0\n",
       "1  Transportation is a large necessity in most co...        0.0\n",
       "2  \"America's love affair with it's vehicles seem...        0.0\n",
       "3  How often do you ride in a car? Do you drive a...        0.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Kaggle AI vs Human\n",
    "kaggle_path = \"../data/raw/kaggle_ai_human.csv\"\n",
    "assert os.path.exists(kaggle_path), f\"{kaggle_path} not found\"\n",
    "\n",
    "df_kaggle = pd.read_csv(kaggle_path)\n",
    "print(\"kaggle_ai_human shape:\", df_kaggle.shape)\n",
    "print(\"kaggle_ai_human columns:\", df_kaggle.columns.tolist())\n",
    "display(df_kaggle.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a13cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routellm_gpt4_dataset shape: (109101, 5)\n",
      "routellm_gpt4_dataset columns: ['prompt', 'source', 'gpt4_response', 'mixtral_response', 'mixtral_score']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "      <th>gpt4_response</th>\n",
       "      <th>mixtral_response</th>\n",
       "      <th>mixtral_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'll give you a review, can you extract the fo...</td>\n",
       "      <td>['lmsys-chat-1m']</td>\n",
       "      <td>Sure, here's the analysis of the review:\\n\\n1....</td>\n",
       "      <td>Food aspects and opinion words:\\n\\n1. Made to ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the following question: Claim: \"Joker m...</td>\n",
       "      <td>['flan_v2_cot']</td>\n",
       "      <td>The answer is no.\\nChain of thoughts: Stan Lee...</td>\n",
       "      <td>The answer is no.\\n\\nChain of thoughts: While ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TASK DEFINITION: In this task you will be give...</td>\n",
       "      <td>['flan_v2_niv2']</td>\n",
       "      <td>ZdoublexpropheciesS</td>\n",
       "      <td>ZdoublexpropheciesS\\n\\nIn this task, you are a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detailed Instructions: In this task, you need ...</td>\n",
       "      <td>['flan_v2_niv2']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No, 'station' is not the longest word in the s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A guy pick up a woman Then he puts her down Ex...</td>\n",
       "      <td>['sharegpt']</td>\n",
       "      <td>This phrase could be interpreted as a joke bec...</td>\n",
       "      <td>This joke is a play on words and relies on the...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt             source  \\\n",
       "0  I'll give you a review, can you extract the fo...  ['lmsys-chat-1m']   \n",
       "1  Answer the following question: Claim: \"Joker m...    ['flan_v2_cot']   \n",
       "2  TASK DEFINITION: In this task you will be give...   ['flan_v2_niv2']   \n",
       "3  Detailed Instructions: In this task, you need ...   ['flan_v2_niv2']   \n",
       "4  A guy pick up a woman Then he puts her down Ex...       ['sharegpt']   \n",
       "\n",
       "                                       gpt4_response  \\\n",
       "0  Sure, here's the analysis of the review:\\n\\n1....   \n",
       "1  The answer is no.\\nChain of thoughts: Stan Lee...   \n",
       "2                                ZdoublexpropheciesS   \n",
       "3                                                Yes   \n",
       "4  This phrase could be interpreted as a joke bec...   \n",
       "\n",
       "                                    mixtral_response  mixtral_score  \n",
       "0  Food aspects and opinion words:\\n\\n1. Made to ...              4  \n",
       "1  The answer is no.\\n\\nChain of thoughts: While ...              5  \n",
       "2  ZdoublexpropheciesS\\n\\nIn this task, you are a...              5  \n",
       "3  No, 'station' is not the longest word in the s...              5  \n",
       "4  This joke is a play on words and relies on the...              5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load routellm_gpt4_dataset\n",
    "route_path = \"../data/raw/routellm_gpt4_dataset.csv\"\n",
    "assert os.path.exists(route_path), f\"{route_path} not found\"\n",
    "\n",
    "df_route = pd.read_csv(route_path)\n",
    "print(\"routellm_gpt4_dataset shape:\", df_route.shape)\n",
    "print(\"routellm_gpt4_dataset columns:\", df_route.columns.tolist())\n",
    "display(df_route.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a73de70",
   "metadata": {},
   "source": [
    "## Normalization Plan (brief)\n",
    "We will convert each dataset to a common two-column format:\n",
    "- `text` (string)\n",
    "- `label` (int) where `0 = human`, `1 = ai`\n",
    "\n",
    "Dataset-specific notes:\n",
    "- HC3: `human_answers` and `chatgpt_answers` are lists (strings that look like lists). We will parse & explode.\n",
    "- gpt_generated: has `source` (human/ai) and `text`.\n",
    "- kaggle: has `text` and `generated` (0/1).\n",
    "- routellm: contains `prompt` (human) and multiple AI response columns; we'll take `prompt` as human and AI response columns as AI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dafdf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Basic cleaning: ensure string, remove HTML tags, emojis, extra whitespace.\n",
    "    Keep stylistic features as detectors rely on writing patterns.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    # Remove emojis (range)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    # Normalize whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fbde21",
   "metadata": {},
   "source": [
    "### Process HC3\n",
    "HC3 stores `human_answers` and `chatgpt_answers` often as Python-like lists in string form.\n",
    "We will:\n",
    "- Convert list-strings into real lists if necessary\n",
    "- Explode both human and chatgpt lists into rows\n",
    "- Assign labels (0=human, 1=ai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331f3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC3 processed rows: 85904\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basically there are many categories of \" Best ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you 're hearing about it , it 's because it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One reason is lots of catagories . However , h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salt is good for not dying in car crashes and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In Minnesota and North Dakota , they tend to u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Basically there are many categories of \" Best ...      0\n",
       "1  If you 're hearing about it , it 's because it...      0\n",
       "2  One reason is lots of catagories . However , h...      0\n",
       "3  salt is good for not dying in car crashes and ...      0\n",
       "4  In Minnesota and North Dakota , they tend to u...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def try_parse_list(x):\n",
    "    # Try parsing a string that looks like a list, else return [x] if not list\n",
    "    if isinstance(x, str) and x.strip().startswith('['):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(x)\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except Exception:\n",
    "            pass\n",
    "    return [x]\n",
    "\n",
    "# human answers\n",
    "hc3_human = df_hc3[['human_answers']].copy()\n",
    "hc3_human['human_answers'] = hc3_human['human_answers'].apply(lambda v: try_parse_list(v))\n",
    "hc3_human = hc3_human.explode('human_answers').rename(columns={'human_answers':'text'})\n",
    "hc3_human['label'] = 0\n",
    "\n",
    "# ai answers\n",
    "hc3_ai = df_hc3[['chatgpt_answers']].copy()\n",
    "hc3_ai['chatgpt_answers'] = hc3_ai['chatgpt_answers'].apply(lambda v: try_parse_list(v))\n",
    "hc3_ai = hc3_ai.explode('chatgpt_answers').rename(columns={'chatgpt_answers':'text'})\n",
    "hc3_ai['label'] = 1\n",
    "\n",
    "# Keep only text + label\n",
    "hc3_proc = pd.concat([hc3_human[['text','label']], hc3_ai[['text','label']]], ignore_index=True)\n",
    "print(\"HC3 processed rows:\", hc3_proc.shape[0])\n",
    "display(hc3_proc.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6abd9",
   "metadata": {},
   "source": [
    "### Process gpt_generated\n",
    "This file already has `source` (human/ai) and `text`. We'll map `source` to labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56db944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_generated processed rows: 1392522\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 Years a Slave: An Analysis of the Film Essa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20+ Social Media Post Ideas to Radically Simpl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022 Russian Invasion of Ukraine in Global Med...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>533 U.S. 27 (2001) Kyllo v. United States: The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Charles Schwab Corporation Case Essay\\n\\nCha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  12 Years a Slave: An Analysis of the Film Essa...      0\n",
       "1  20+ Social Media Post Ideas to Radically Simpl...      0\n",
       "2  2022 Russian Invasion of Ukraine in Global Med...      0\n",
       "3  533 U.S. 27 (2001) Kyllo v. United States: The...      0\n",
       "4  A Charles Schwab Corporation Case Essay\\n\\nCha...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize column names if necessary\n",
    "df_gpt_proc = df_gpt.copy()\n",
    "# Map source -> label (if not already)\n",
    "if 'source' in df_gpt_proc.columns:\n",
    "    df_gpt_proc['label'] = df_gpt_proc['source'].map({'human':0, 'ai':1})\n",
    "else:\n",
    "    # fallback if already has label\n",
    "    if 'label' not in df_gpt_proc.columns:\n",
    "        raise ValueError(\"gpt_generated missing label/source column\")\n",
    "# Keep only text and label\n",
    "df_gpt_proc = df_gpt_proc[['text','label']]\n",
    "print(\"gpt_generated processed rows:\", df_gpt_proc.shape[0])\n",
    "display(df_gpt_proc.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08edb9ae",
   "metadata": {},
   "source": [
    "### Process kaggle_ai_human\n",
    "Kaggle file has `text` and `generated` where 0=human, 1=ai. We will rename `generated` to `label`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52751d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle processed rows: 487235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Cars. Cars have been around since they became ...      0\n",
       "1  Transportation is a large necessity in most co...      0\n",
       "2  \"America's love affair with it's vehicles seem...      0\n",
       "3  How often do you ride in a car? Do you drive a...      0\n",
       "4  Cars are a wonderful thing. They are perhaps o...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_kaggle_proc = df_kaggle.copy()\n",
    "# If generated is float (0.0/1.0), cast to int\n",
    "if 'generated' in df_kaggle_proc.columns:\n",
    "    df_kaggle_proc['label'] = df_kaggle_proc['generated'].astype(int)\n",
    "else:\n",
    "    # try other names\n",
    "    possible = [c for c in df_kaggle_proc.columns if 'gen' in c.lower()]\n",
    "    if possible:\n",
    "        df_kaggle_proc['label'] = df_kaggle_proc[possible[0]].astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"kaggle dataset doesn't have 'generated' column\")\n",
    "df_kaggle_proc = df_kaggle_proc[['text','label']]\n",
    "print(\"kaggle processed rows:\", df_kaggle_proc.shape[0])\n",
    "display(df_kaggle_proc.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf1efb",
   "metadata": {},
   "source": [
    "### Process routellm_gpt4_dataset\n",
    "This dataset includes `prompt` (human) and AI responses (`gpt4_response`, `mixtral_response`, ...).  \n",
    "We will:\n",
    "- use `prompt` as human samples\n",
    "- extract AI responses as AI samples\n",
    "Note: keep only non-empty strings and later clean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0bc8481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routellm processed rows: 327303\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'll give you a review, can you extract the fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the following question: Claim: \"Joker m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TASK DEFINITION: In this task you will be give...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detailed Instructions: In this task, you need ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A guy pick up a woman Then he puts her down Ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I'll give you a review, can you extract the fo...      0\n",
       "1  Answer the following question: Claim: \"Joker m...      0\n",
       "2  TASK DEFINITION: In this task you will be give...      0\n",
       "3  Detailed Instructions: In this task, you need ...      0\n",
       "4  A guy pick up a woman Then he puts her down Ex...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build human and ai frames from routellm\n",
    "route_frames = []\n",
    "\n",
    "# human prompts\n",
    "if 'prompt' in df_route.columns:\n",
    "    df_r_human = df_route[['prompt']].rename(columns={'prompt':'text'})\n",
    "    df_r_human['label'] = 0\n",
    "    route_frames.append(df_r_human)\n",
    "\n",
    "# AI response columns to include (check which exist)\n",
    "ai_cols = [c for c in ['gpt4_response','mixtral_response','anthropic_response','model_response'] if c in df_route.columns]\n",
    "# if mixtral_response exists, include it, and gpt4_response if present\n",
    "for c in ai_cols:\n",
    "    tmp = df_route[[c]].rename(columns={c:'text'}).copy()\n",
    "    tmp['label'] = 1\n",
    "    route_frames.append(tmp)\n",
    "\n",
    "df_route_proc = pd.concat(route_frames, ignore_index=True)\n",
    "print(\"routellm processed rows:\", df_route_proc.shape[0])\n",
    "display(df_route_proc.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d1760",
   "metadata": {},
   "source": [
    "## Concatenate all processed datasets\n",
    "Now we will concatenate the processed frames from HC3, GPT-generated, Kaggle, and RouteLLM into a single DataFrame.\n",
    "We will then:\n",
    "- clean text\n",
    "- drop nulls and very short texts\n",
    "- deduplicate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c50a74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames lengths: [85904, 1392522, 487235, 327303]\n",
      "Combined rows before cleaning: 2292964\n",
      "Combined rows before cleaning: 2292964\n",
      "Rows after removing short & duplicates: 2170318 (removed 112904)\n",
      "Rows after removing short & duplicates: 2170318 (removed 112904)\n",
      "Final dataset shape: (2170318, 2)\n",
      "Final dataset shape: (2170318, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ime, making bank for minutes, selling my body ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jessica. I am so sorry. I wished we did things...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016 Local Elections We want more Kiwis to get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Department of Human Services has created t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>``Why am I here,'' I think to myself. I'm stan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  ime, making bank for minutes, selling my body ...      0\n",
       "1  Jessica. I am so sorry. I wished we did things...      0\n",
       "2  2016 Local Elections We want more Kiwis to get...      0\n",
       "3  The Department of Human Services has created t...      1\n",
       "4  ``Why am I here,'' I think to myself. I'm stan...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collect all processed frames\n",
    "frames = [hc3_proc, df_gpt_proc, df_kaggle_proc, df_route_proc]\n",
    "print(\"Frames lengths:\", [f.shape[0] for f in frames])\n",
    "\n",
    "full_df = pd.concat(frames, ignore_index=True)\n",
    "print(\"Combined rows before cleaning:\", full_df.shape[0])\n",
    "\n",
    "# Basic cleaning + dropna\n",
    "# Limit maximum text length to avoid giant files\n",
    "MAX_CHARS = 1500\n",
    "full_df['text'] = full_df['text'].astype(str).apply(clean_text).str.slice(0, MAX_CHARS)\n",
    "# Remove empty or too short texts (e.g., < 20 chars)\n",
    "full_df['text_len'] = full_df['text'].str.len()\n",
    "full_df = full_df[full_df['text_len'] >= 20].copy()\n",
    "# Drop duplicates\n",
    "before = full_df.shape[0]\n",
    "full_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "after = full_df.shape[0]\n",
    "print(f\"Rows after removing short & duplicates: {after} (removed {before-after})\")\n",
    "\n",
    "# Keep only text and label\n",
    "full_df = full_df[['text','label']].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Final dataset shape:\", full_df.shape)\n",
    "display(full_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cd89f",
   "metadata": {},
   "source": [
    "## Class balance check\n",
    "We should see how many human vs AI samples we have after merge. If classes are heavily imbalanced, we may need to handle it (resampling, class weights, or sampling subsets for training).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dc57526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1417533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>752785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   counts\n",
       "0      0  1417533\n",
       "1      1   752785"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['label'].value_counts().rename_axis('label').reset_index(name='counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa31d62",
   "metadata": {},
   "source": [
    "## Train / Validation / Test split\n",
    "We'll use a standard split: 70% train, 15% validation, 15% test.\n",
    "We will stratify by `label` to preserve class balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "519f63f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1519222, 2) Val: (325548, 2) Test: (325548, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(full_df, test_size=0.30, random_state=42, stratify=full_df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e224db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2187357, 2)\n"
     ]
    }
   ],
   "source": [
    "print(full_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc833a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2187357\n"
     ]
    }
   ],
   "source": [
    "print(full_df['text'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c57629cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  eve what he was seeing. Throughout the room wa...      0\n",
      "1  Title: \"The King's Legacy\" In the vast, rugged...      1\n",
      "2  Organisation of the Organisationless: The Ques...      0\n",
      "3  aised her eyebrow again. “ Registered? We regi...      0\n",
      "4  There is no doubt that successful people often...      1\n"
     ]
    }
   ],
   "source": [
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48a40ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.170318e+06\n",
      "mean     1.120267e+03\n",
      "std      4.371374e+02\n",
      "min      2.000000e+01\n",
      "25%      9.540000e+02\n",
      "50%      1.242000e+03\n",
      "75%      1.500000e+03\n",
      "max      1.500000e+03\n",
      "Name: text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(full_df['text'].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e6dd395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    1429280\n",
      "1     758077\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(full_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "110392fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train/val/test in data/processed/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "train_df.to_csv(\"../data/processed/train.csv\", index=False)\n",
    "val_df.to_csv(\"../data/processed/val.csv\", index=False)\n",
    "test_df.to_csv(\"../data/processed/test.csv\", index=False)\n",
    "print(\"Saved train/val/test in data/processed/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c7c24",
   "metadata": {},
   "source": [
    "## Sanity checks\n",
    "- Print a few positive (AI) and negative (human) examples from train set\n",
    "- Print label distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21795289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    992273\n",
       "1    526949\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example human text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"reflection had... *something* that I didn't. A quick glance down at my chest determined that to be true ; I had a definite lack of mammaries, which was, of course, normal for a guy. I squinted and leaned forward, and almost thought that the reflection was ever-so-slightly delayed in mimicking me. It must've been some kind of carnival mirror effect, I decided. I snickered, and turned to the side, ``admiring'' the strange mirror. Maybe I was still dreaming. A shift in the reflection caught my attention ; its eyes had *definitely* moved. ``What the...?'' I asked nobody, leaning closer again. A thought popped into my head, and I moved to the edge of the mirror, looking across its surface. Yeah, it *looked* flat. Flat as *my* chest. I stepped back and regarded the reflection once more. Yeah, now that I'd looked closely, I could tell more that was off. Its skin was just a hair lighter. Less hairy arms, for sure. Finer features. Maybe a bit shorter. And a hand to my face (\",\n",
       " \"We were able to locate the event, but you do not have permission to view this event. Aaron Watson with Special Guest Kevin Fowler & Josh Ward Foster Communications Coliseum San Angelo, TX Saturday December 01, 2018 07:30 PM Buy Now Cheech and Chong Buffalo Run Casino Miami, OK Friday October 26, 2018 08:00 PM Buy Now West Texas Food Truck Festival with 38 Special Back Porch of Texas Abilene, TX Saturday October 06, 2018 Buy Now Rock'n On The River with 38 Special Bill Aylor Sr. Memorial RiverStage San Angelo, TX Sunday October 07, 2018 Buy Now 2018 Miami Police Department Airplane Lottery Miami Police Dept Miami, OK Date TBD Buy Now\",\n",
       " 'The blaring went off a few feet from my ear, and I was yanked from the dream world back to reality as my arm flailed to deactivate my alarm. Eternity shrank to seconds as I slowly opened my eyes and saw the rapidly blinking 6:00 turn to 6:01. My waking brain would take minutes to begin functioning ; in my unconscious I saw them by the hundreds, all unfamiliar to me. Had there been ten, I couldn ’ t pick myself out of a lineup. I sat up and rubbed the sleep out of my eyes. My arms felt heavy, and then in the dim light my gaze found the tumbler upon my nightstand. The escape from sobriety with the subtle help of alcohol eased my mind seven days a week. I knew the risks I took by imbibing so much, but in my situation where could the blame be placed? After shaving, pissing, and donning my running garb, I set out from my overpriced, undersized studio apartment to log a few miles. That upcoming marathon wouldn ’ t run itself, ya know. The clock had yet to strike seven a.m. but th']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example AI text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"You'll need to contact the admissions office at the community college and let them know that you're interested in enrolling in classes. They will be able to provide more information on how to proceed with the application and enrollment process.\",\n",
       " 'In an attempt to increase sales at every level, Walmart launched an ad campaign for Black Friday, but in so doing they unwittingly sparked an uproar that they now can\\'t get out of. It all started when Walmart invited the New York City-based Black Youth Project 100 to perform at the company\\'s Black Friday 2013, but the group didn\\'t like that because the group had protested the US immigration system over the summer in a series of protests. To get around this, Walmart enlisted a PR firm and the group released a statement via Billboard that said that they were only invited to perform at the event, and that the invitation was \"invalid.\" But despite the fact that the invitation was only for a private event (and the fact that Black Lives Matter has a list of demands, not something to be taken literally), Walmart has since launched an ad campaign that features young celebrities like Common, T.I., T.I. and Waka Flocka Flame performing for Black Friday. The company wants to make sure that people buy everything on sale while encouraging them to not purchase anything that will make the company a profit. \"Black Friday is one of the biggest shopping days of the year. It is also part of the biggest Black Friday controversy ever. In the run up to the start of the holiday shoppers get to buy everything they might want, and Walmart, who has a lot riding on the holiday, wanted to make sure they had their cake and eat it too,\" explained Salon\\'s Matt Wuerker. But because Walmart is a publicly tra',\n",
       " 'I\\'ve never been so pleased by the simple concept of a smartphone holder! It will definitely become a part of my \"always on\" set up. The \"phone holder\" for iPhone is a clever way of incorporating the phone into your desk-top. The holder snaps on over your laptop and has a built in USB and headphone jack as well as the power jack for your iPhone.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train label distribution\")\n",
    "display(train_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nExample human text:\")\n",
    "display(train_df[train_df['label']==0]['text'].sample(3).tolist())\n",
    "\n",
    "print(\"\\nExample AI text:\")\n",
    "display(train_df[train_df['label']==1]['text'].sample(3).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba21b4",
   "metadata": {},
   "source": [
    "## Optional: Save a smaller dev set for quick experiments\n",
    "Create a small balanced dev set (e.g., 5k samples) for fast debugging on local machines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "201783ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved small dev set with shape: (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create small balanced sample (if dataset is large)\n",
    "min_class = min(train_df['label'].value_counts().min(), 2500)  # max 2.5k per class or less if limited\n",
    "dev_samples = pd.concat([\n",
    "    train_df[train_df['label']==0].sample(n=min_class, random_state=42),\n",
    "    train_df[train_df['label']==1].sample(n=min_class, random_state=42)\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "dev_samples.to_csv(\"../data/processed/dev_small.csv\", index=False)\n",
    "print(\"Saved small dev set with shape:\", dev_samples.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_detector_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
